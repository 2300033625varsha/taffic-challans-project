# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D5GhSfL_h66prjEfLwvqJdGyLBX8zo_-
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

print("\nðŸ”§ 9. TF-IDF TECHNIQUE")
print("="*50)

class TFIDFDemo:
    def __init__(self):
        self.vectorizer = TfidfVectorizer()

    def demonstrate_tfidf(self, documents):
        """Demonstrate TF-IDF transformation"""
        print("DOCUMENT COLLECTION:")
        print("-" * 60)
        for i, doc in enumerate(documents, 1):
            print(f"Doc {i}: {doc}")

        # Create TF-IDF model
        X = self.vectorizer.fit_transform(documents)
        feature_names = self.vectorizer.get_feature_names_out()

        print(f"\nVOCABULARY ({len(feature_names)} words):")
        print(feature_names)

        # Convert to DataFrame for better visualization
        tfidf_df = pd.DataFrame(X.toarray(), columns=feature_names)

        print(f"\nTF-IDF MATRIX:")
        print("Rows: Documents, Columns: Words, Values: TF-IDF Scores")
        print(tfidf_df.round(3))

        return X, feature_names, tfidf_df

    def explain_tfidf_calculation(self, documents):
        """Explain TF-IDF calculation step by step"""
        print("\n" + "="*60)
        print("TF-IDF CALCULATION EXPLANATION")
        print("="*60)

        # Manual TF-IDF calculation for a simple example
        simple_docs = [
            "helmet riding motorcycle",
            "speeding vehicle highway",
            "signal jumping intersection"
        ]

        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(simple_docs)

        # Get vocabulary and IDF values
        feature_names = vectorizer.get_feature_names_out()
        idf_values = vectorizer.idf_

        print("Vocabulary and IDF values:")
        for word, idf in zip(feature_names, idf_values):
            print(f"  {word}: IDF = {idf:.3f}")

        print(f"\nTF-IDF Matrix:")
        tfidf_matrix = pd.DataFrame(X.toarray(), columns=feature_names)
        print(tfidf_matrix.round(3))

    def document_similarity(self, documents):
        """Calculate document similarity using TF-IDF"""
        print("\n" + "="*60)
        print("DOCUMENT SIMILARITY WITH TF-IDF")
        print("="*60)

        # Compute TF-IDF
        X = self.vectorizer.fit_transform(documents)

        # Calculate cosine similarity
        similarity_matrix = cosine_similarity(X)

        print("Cosine Similarity Matrix:")
        similarity_df = pd.DataFrame(
            similarity_matrix,
            index=[f"Doc{i+1}" for i in range(len(documents))],
            columns=[f"Doc{i+1}" for i in range(len(documents))]
        )
        print(similarity_df.round(3))

        # Find most similar documents
        print("\nMost Similar Document Pairs:")
        for i in range(len(documents)):
            for j in range(i+1, len(documents)):
                similarity = similarity_matrix[i, j]
                print(f"Doc{i+1} vs Doc{j+1}: {similarity:.3f}")

    def keyword_extraction(self, documents):
        """Extract important keywords using TF-IDF"""
        print("\n" + "="*60)
        print("KEYWORD EXTRACTION WITH TF-IDF")
        print("="*60)

        X = self.vectorizer.fit_transform(documents)
        feature_names = self.vectorizer.get_feature_names_out()

        # Get average TF-IDF scores for each word across documents
        avg_tfidf_scores = X.mean(axis=0).A1
        word_scores = list(zip(feature_names, avg_tfidf_scores))

        # Sort by TF-IDF score
        word_scores.sort(key=lambda x: x[1], reverse=True)

        print("Top Keywords by TF-IDF Score:")
        for word, score in word_scores[:10]:
            print(f"  {word}: {score:.3f}")

        return word_scores

# Test TF-IDF
tfidf_demo = TFIDFDemo()

# Sample violation documents
violation_docs = [
    "driver riding motorcycle without helmet protection",
    "vehicle speeding over limit on national highway",
    "car jumping red traffic signal at busy intersection",
    "motorcycle triple riding with multiple passengers",
    "driver using mobile phone while driving vehicle"
]

# Basic TF-IDF demonstration
X_tfidf, features, tfidf_df = tfidf_demo.demonstrate_tfidf(violation_docs)

# TF-IDF calculation explanation
tfidf_demo.explain_tfidf_calculation(violation_docs)

# Document similarity
tfidf_demo.document_similarity(violation_docs)

# Keyword extraction
keywords = tfidf_demo.keyword_extraction(violation_docs)

# Comparison with Bag-of-Words
print("\n" + "="*60)
print("TF-IDF vs BAG-OF-WORDS COMPARISON")
print("="*60)

# Same documents, different vectorization
bow_vectorizer = CountVectorizer()
tfidf_vectorizer = TfidfVectorizer()

X_bow = bow_vectorizer.fit_transform(violation_docs)
X_tfidf = tfidf_vectorizer.fit_transform(violation_docs)

# Compare feature weights
sample_doc_idx = 0
bow_weights = X_bow[sample_doc_idx].toarray()[0]
tfidf_weights = X_tfidf[sample_doc_idx].toarray()[0]

bow_features = bow_vectorizer.get_feature_names_out()
tfidf_features = tfidf_vectorizer.get_feature_names_out()

print("Comparison for Document 1:")
print(f"{'Word':<15} {'BOW Count':<10} {'TF-IDF Score':<12}")
print("-" * 40)

# Get top words by TF-IDF
top_indices = tfidf_weights.argsort()[-10:][::-1]

for idx in top_indices:
    word = tfidf_features[idx]
    bow_idx = np.where(bow_features == word)[0]
    if len(bow_idx) > 0:
        bow_count = bow_weights[bow_idx[0]]
        tfidf_score = tfidf_weights[idx]
        print(f"{word:<15} {bow_count:<10} {tfidf_score:.4f}")