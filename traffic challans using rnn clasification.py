# -*- coding: utf-8 -*-
"""Untitled46.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12wG4Ww-j3_8mmYxSk2b6MJlytJrgEiiB
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder

print("ðŸ”§ 1. RNN FOR TEXT CLASSIFICATION")
print("="*50)

# Create sample violation text data
violation_texts = [
    "riding without helmet on motorcycle",
    "speeding over limit on highway",
    "jumping red signal at intersection",
    "triple riding on two wheeler",
    "using mobile phone while driving",
    "drunk driving detected by police",
    "no parking violation in restricted zone",
    "wrong side driving on one way",
    "no insurance documents for vehicle",
    "pollution certificate expired",
    "overloading goods vehicle",
    "driving without valid license",
    "seat belt violation in car",
    "illegal vehicle modification",
    "reckless driving dangerous overtaking"
]

violation_types = [
    'Helmet', 'Speeding', 'Signal', 'Triple', 'Mobile',
    'Drunk', 'Parking', 'WrongSide', 'Insurance', 'Pollution',
    'Overload', 'License', 'SeatBelt', 'Modification', 'Reckless'
]

# Create expanded dataset
def expand_dataset(texts, labels, num_samples=200):
    expanded_texts = []
    expanded_labels = []

    for i in range(num_samples):
        idx = i % len(texts)
        text = texts[idx]
        label = labels[idx]

        # Add some variations
        variations = [
            f"Driver was caught {text}",
            f"Vehicle found {text}",
            f"Police observed {text}",
            f"Traffic violation: {text}",
            f"Incident involving {text}"
        ]

        expanded_texts.append(variations[i % len(variations)])
        expanded_labels.append(label)

    return expanded_texts, expanded_labels

# Expand the dataset
X_text, y_labels = expand_dataset(violation_texts, violation_types)

# Convert labels to numerical values
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_labels)

# Text preprocessing and tokenization
tokenizer = Tokenizer(num_words=1000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_text)
X_sequences = tokenizer.texts_to_sequences(X_text)

# Pad sequences
max_length = 20
X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='post')

# Split the data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_padded, y_encoded, test_size=0.2, random_state=42
)

# Build RNN model
vocab_size = len(tokenizer.word_index) + 1
embedding_dim = 50
rnn_units = 64

model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=max_length),
    SimpleRNN(rnn_units, return_sequences=False),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y_encoded)), activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

print("RNN Model Architecture:")
model.summary()

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=16,
    validation_data=(X_test, y_test),
    verbose=1
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"\nðŸ“Š RNN Model Evaluation:")
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Loss: {test_loss:.4f}")

# Make predictions
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

print(f"\nSample Predictions:")
for i in range(5):
    original_text = tokenizer.sequences_to_texts([X_test[i]])[0]
    true_label = label_encoder.inverse_transform([y_test[i]])[0]
    pred_label = label_encoder.inverse_transform([y_pred_classes[i]])[0]
    print(f"Text: {original_text}")
    print(f"True: {true_label}, Predicted: {pred_label}")
    print("-" * 50)