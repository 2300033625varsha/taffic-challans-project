# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D5GhSfL_h66prjEfLwvqJdGyLBX8zo_-
"""

print("\nðŸ”§ 7. TEXT NORMALIZATION")
print("="*50)

class TextNormalizer:
    def __init__(self):
        self.lemmatizer = WordNetLemmatizer()

        # Common abbreviations in traffic context
        self.abbreviations = {
            'kmph': 'kilometers per hour',
            'mph': 'miles per hour',
            'hr': 'hour',
            'min': 'minute',
            'sec': 'second',
            'no.': 'number',
            'st': 'street',
            'rd': 'road',
            'ave': 'avenue',
            'blvd': 'boulevard',
            'hw': 'highway',
            'exp': 'expressway',
            'int': 'intersection',
            'sig': 'signal',
            'veh': 'vehicle',
            'lic': 'license',
            'ins': 'insurance',
            'doc': 'document'
        }

        # Number to word mapping
        self.number_words = {
            '1': 'one', '2': 'two', '3': 'three', '4': 'four', '5': 'five',
            '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine', '10': 'ten'
        }

    def to_lowercase(self, text):
        """Convert text to lowercase"""
        return text.lower()

    def expand_abbreviations(self, text):
        """Expand common abbreviations"""
        words = text.split()
        expanded_words = []

        for word in words:
            if word.lower() in self.abbreviations:
                expanded_words.append(self.abbreviations[word.lower()])
            else:
                expanded_words.append(word)

        return ' '.join(expanded_words)

    def numbers_to_words(self, text):
        """Convert numbers to words"""
        for num, word in self.number_words.items():
            text = text.replace(num, word)
        return text

    def remove_special_characters(self, text, keep_pattern=r'[^a-zA-Z0-9\s]'):
        """Remove special characters"""
        return re.sub(keep_pattern, '', text)

    def normalize_whitespace(self, text):
        """Normalize whitespace"""
        return ' '.join(text.split())

    def lemmatize_text(self, text):
        """Apply lemmatization to text"""
        tokens = word_tokenize(text)
        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in tokens]
        return ' '.join(lemmatized_tokens)

    def full_normalization_pipeline(self, text):
        """Complete text normalization pipeline"""
        print(f"Original: {text}")

        # Step 1: Lowercase
        text = self.to_lowercase(text)
        print(f"Lowercase: {text}")

        # Step 2: Expand abbreviations
        text = self.expand_abbreviations(text)
        print(f"Abbreviations Expanded: {text}")

        # Step 3: Convert numbers to words
        text = self.numbers_to_words(text)
        print(f"Numbers Converted: {text}")

        # Step 4: Remove special characters
        text = self.remove_special_characters(text)
        print(f"Special Characters Removed: {text}")

        # Step 5: Normalize whitespace
        text = self.normalize_whitespace(text)
        print(f"Whitespace Normalized: {text}")

        # Step 6: Lemmatization
        text = self.lemmatize_text(text)
        print(f"Lemmatized: {text}")

        return text

# Test text normalization
normalizer = TextNormalizer()

test_texts = [
    "Driver was going 80 kmph on HW 65",
    "Car jumped RED signal at 5th St & Main Rd",
    "3 people on 1 motorcycle - triple riding violation",
    "Vehicle No. AP07AB1234 without ins. doc"
]

print("TEXT NORMALIZATION PIPELINE:")
print("="*70)

for i, text in enumerate(test_texts, 1):
    print(f"\nExample {i}:")
    normalized = normalizer.full_normalization_pipeline(text)
    print(f"Final Normalized: {normalized}")
    print("-" * 70)

# Batch normalization example
print("\nBATCH NORMALIZATION EXAMPLE:")
print("="*50)

violation_records = [
    "Speed: 90 kmph on NH16",
    "Signal jump at 3rd signal",
    "No helmet - 2 riders",
    "Mobile use while driving veh"
]

normalized_records = [normalizer.full_normalization_pipeline(text) for text in violation_records]

print("\nNormalized Records:")
for orig, norm in zip(violation_records, normalized_records):
    print(f"Before: {orig}")
    print(f"After:  {norm}")
    print("-" * 40)