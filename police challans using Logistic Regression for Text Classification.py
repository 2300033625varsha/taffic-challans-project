# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D5GhSfL_h66prjEfLwvqJdGyLBX8zo_-
"""

from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import numpy as np

print("\nðŸ”§ 2. LOGISTIC REGRESSION FOR TEXT CLASSIFICATION")
print("="*50)

# Define placeholder variables for violation_texts and violation_types
# Replace these with your actual data
violation_texts = ["This is a text about a violation.", "Another text describing a different violation.", "A third example of violation text."]
violation_types = ["Type A", "Type B", "Type A"]


# Use the same dataset
X_text, y_labels = expand_dataset(violation_texts, violation_types, 300)

# Convert labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_labels)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X_text, y_encoded, test_size=0.2, random_state=42
)

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(
    max_features=1000,
    stop_words='english',
    ngram_range=(1, 2)
)

X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

print(f"TF-IDF Matrix Shape: {X_train_tfidf.shape}")

# Train Logistic Regression model
lr_model = LogisticRegression(
    multi_class='multinomial',
    solver='lbfgs',
    max_iter=1000,
    random_state=42
)

lr_model.fit(X_train_tfidf, y_train)

# Evaluate the model
y_pred = lr_model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)

print(f"\nðŸ“Š Logistic Regression Results:")
print(f"Accuracy: {accuracy:.4f}")
print(f"\nClassification Report:")
print(classification_report(y_test, y_pred,
                          target_names=label_encoder.classes_))

# Feature importance analysis
feature_names = tfidf_vectorizer.get_feature_names_out()
print(f"\nTop 10 Most Important Features:")
# Check the shape of coef_ to handle binary and multi-class cases
if lr_model.coef_.shape[0] == 1:
    # Binary case, coef_ is a single row
    coefs = [lr_model.coef_[0]]
else:
    # Multi-class case, coef_ has a row for each class
    coefs = lr_model.coef_

for i, coef in enumerate(coefs):
    # Ensure the class index is within the bounds of label_encoder.classes_
    if i < len(label_encoder.classes_):
        class_name = label_encoder.classes_[i]
        top_indices = coef.argsort()[-10:][::-1]
        top_features = [feature_names[idx] for idx in top_indices]
        print(f"{class_name}: {top_features}")
    else:
        print(f"Warning: Skipping feature importance for class index {i} as it is out of bounds.")


# Confusion Matrix
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)

# Get unique classes from both actual and predicted values in the test set
unique_classes_encoded = np.unique(np.concatenate((y_test, y_pred)))
# Map encoded class indices back to original class names using label_encoder.classes_
cm_labels = [label_encoder.classes_[i] for i in unique_classes_encoded]


sns.heatmap(cm, annot=True, fmt='d',
            xticklabels=cm_labels,
            yticklabels=cm_labels,
            cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

# Placeholder for expand_dataset function
# Replace this with your actual implementation of expand_dataset
def expand_dataset(texts, labels, multiplier):
  """
  This is a placeholder function for expand_dataset.
  Replace this with your actual implementation.
  """
  # Example placeholder implementation:
  expanded_texts = texts * multiplier
  expanded_labels = labels * multiplier
  return expanded_texts, expanded_labels

# You may also need to define or import violation_texts and violation_types
# For example:
# violation_texts = ["text1", "text2"]
# violation_types = ["typeA", "typeB"]

# And import LabelEncoder and train_test_split if not already done
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split